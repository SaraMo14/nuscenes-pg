{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from example.discretizer.discretizer_d0  import AVDiscretizer\n",
    "from example.discretizer.discretizer_d1  import AVDiscretizerD1\n",
    "from example.discretizer.utils import Action\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pgeon.policy_graph as PG\n",
    "from example.environment import SelfDrivingEnvironment\n",
    "from nuscenes import NuScenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path where you stored the copy of the nuScenes dataset.\n",
    "DATAROOT = Path('/home/saramontese/Desktop/MasterThesis/example/dataset/data/sets/nuscenes')\n",
    "\n",
    "#MINI\n",
    "nuscenes = NuScenes('v1.0-mini', dataroot=DATAROOT)\n",
    "\n",
    "#FULL\n",
    "#nuscenes = NuScenes('v1.0-trainval', dataroot=DATAROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the following columns for each state of the self-driving car:\n",
    "\n",
    "- instance_token: A unique identifier for the vehicle instance.\n",
    "- translation: The vehicle's position in 3D space (x, y, z coordinates).\n",
    "- yaw: The orientation of the vehicle around the vertical axis (rotation angle).\n",
    "- velocity: The vehicle's speed in a given direction.\n",
    "- acceleration: The change in velocity over time.\n",
    "- heading_change_rate: The rate of change of the vehicle's direction.\n",
    "- timestamp: The time at which the state was recorded.\n",
    "- scene_token: A unique identifier for the scenario or environment the vehicle is in\n",
    "- detected_objects: detected objects in the surrounding of the vehicle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV data into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_dict = {\n",
    "    'modality': 'category',  # for limited set of modalities, 'category' is efficient\n",
    "    'scene_token': 'str',  \n",
    "    'timestamp': 'str',  # To enable datetime operations\n",
    "    'rotation': 'object',  # Quaternion (lists)\n",
    "    'x': 'float64',\n",
    "    'y': 'float64',\n",
    "    'z': 'float64',\n",
    "    'yaw': 'float64',  \n",
    "    'velocity': 'float64',\n",
    "    'acceleration': 'float64',\n",
    "    'heading_change_rate': 'float64',\n",
    "    'delta_local_x': 'float64',\n",
    "    'delta_local_y': 'float64'}\n",
    "df = pd.read_csv(DATAROOT / 'train_v1.0-mini_lidar_3.csv', dtype=dtype_dict, parse_dates=['timestamp'])\n",
    "city ='singapore-onenorth'  #'boston-seaport'#boston-seaport'#\n",
    "df = df[df['location'] == city]\n",
    "#df['detect_CAM_FRONT'] = df['detect_CAM_FRONT'].apply(lambda x: ast.literal_eval(x))\n",
    "#df['detect_CAM_BACK'] = df['detect_CAM_BACK'].apply(lambda x: ast.literal_eval(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory of AV in a Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do an example of computing trajectory of a vehicle in a scene. We then check if the rendering of the scene match the computed trajectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cc8c0bf57f984915a77078b10eb33198'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scene_token'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a scene and test the  algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_test = df['scene_token'].unique()[0]\n",
    "example_scene_df = df[df['scene_token']==scene_test]\n",
    "example_scene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the trajectoy of the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SelfDrivingEnvironment(city,dataroot=DATAROOT)\n",
    "av_discretizer = AVDiscretizer(env)\n",
    "pg = PG.PolicyGraph(env, av_discretizer)\n",
    "pg = pg.fit(df, update=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To render the scene (video):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuscenes.render_scene(scene_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = SelfDrivingEnvironment(city='all')\n",
    "discretizer = AVDiscretizerD1(environment, obj_discretization='multiple', vel_discretization='multiple')\n",
    "nodes_path = f'example/dataset/data/policy_graphs/PG_mini_Call_D1c_Wall_Tall_nodes.csv'\n",
    "edges_path = f'example/dataset/data/policy_graphs/PG_mini_Call_D1c_Wall_Tall_edges.csv'\n",
    "pg = PG.PolicyGraph.from_nodes_and_edges(nodes_path, edges_path, environment, discretizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 161\n",
      "Number of edges: 258\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {len(pg.nodes)}')\n",
    "print(f'Number of edges: {len(pg.edges)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PedestrianNearby(1-3), IsTwoWheelNearby(NO), BlockProgress(START), LanePosition(RIGHT), NextIntersection(NONE), Velocity(STOPPED), Rotation(RIGHT), IsStopSignNearby(NO), IsZebraNearby(YES), IsTrafficLightNearby(YES), FrontRightObjects(1-3)), FrontLeftObjects(1-3)))\n",
      "  Times visited: 5\n",
      "  p(s):          0.015\n"
     ]
    }
   ],
   "source": [
    "arbitrary_state = list(pg.nodes)[9]\n",
    "\n",
    "print(arbitrary_state)\n",
    "print(f'  Times visited: {pg.nodes[arbitrary_state][\"frequency\"]}')\n",
    "print(f'  p(s):          {pg.nodes[arbitrary_state][\"probability\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From:    (PedestrianNearby(0), IsTwoWheelNearby(YES), BlockProgress(INTERSECTION), LanePosition(RIGHT), NextIntersection(NONE), Velocity(LOW), Rotation(RIGHT), IsStopSignNearby(NO), IsZebraNearby(YES), IsTrafficLightNearby(YES), FrontRightObjects(1-3)), FrontLeftObjects(0)))\n",
      "Action:  9\n",
      "To:      (PedestrianNearby(0), IsTwoWheelNearby(YES), BlockProgress(INTERSECTION), LanePosition(RIGHT), NextIntersection(NONE), Velocity(LOW), Rotation(RIGHT), IsStopSignNearby(NO), IsZebraNearby(YES), IsTrafficLightNearby(YES), FrontRightObjects(4+)), FrontLeftObjects(0)))\n",
      "  Times visited:      1\n",
      "  p(s_to,a | s_from): 0.500\n"
     ]
    }
   ],
   "source": [
    "arbitrary_edge = list(pg.edges)[20]\n",
    "\n",
    "print(f'From:    {arbitrary_edge[0]}')\n",
    "print(f'Action:  {arbitrary_edge[2]}')\n",
    "print(f'To:      {arbitrary_edge[1]}')\n",
    "print(f'  Times visited:      {pg[arbitrary_edge[0]][arbitrary_edge[1]][arbitrary_edge[2]][\"frequency\"]}')\n",
    "print(f'  p(s_to,a | s_from): {pg[arbitrary_edge[0]][arbitrary_edge[1]][arbitrary_edge[2]][\"probability\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PG-based policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgeon.policy_graph import PGBasedPolicy, PGBasedPolicyMode, PGBasedPolicyNodeNotFoundMode\n",
    "\n",
    "from example.discretizer.utils import PedestrianNearby, BlockProgress, IsTwoWheelNearby, IsTrafficLightNearby,IsZebraNearby,IsStopSignNearby, FrontLeftObjects, FrontRightObjects, Action, LanePosition, BlockProgress, NextIntersection, Velocity, Rotation\n",
    "\n",
    "from pgeon.discretizer import  Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Graph with PGBasedPolicyMode.STOCHASTIC and PGBasedPolicyNodeNotFoundMode.FIND_SIMILAR_NODES\n",
      "PG number of nodes: 161\n",
      "PG number of edges: 258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_mode = PGBasedPolicyMode.STOCHASTIC\n",
    "node_not_found_mode = PGBasedPolicyNodeNotFoundMode.FIND_SIMILAR_NODES\n",
    "\n",
    "policy = PGBasedPolicy(pg, policy_mode,node_not_found_mode )\n",
    "pg._normalize()\n",
    "print(f'Policy Graph with {policy_mode} and {node_not_found_mode}')\n",
    "print(f'PG number of nodes: {len(policy.pg.nodes)}')\n",
    "print(f'PG number of edges: {len(policy.pg.edges)}')\n",
    "        \n",
    "\n",
    "\n",
    "initial_state = list(pg.nodes)[1]  \n",
    "#final_state = list(pg.nodes)[5]\n",
    "action = policy.act(initial_state)\n",
    "\n",
    "action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PedestrianNearby(0) IsTwoWheelNearby(YES) BlockProgress(INTERSECTION) LanePosition(RIGHT) NextIntersection(NONE) Velocity(LOW) Rotation(RIGHT) IsStopSignNearby(NO) IsZebraNearby(YES) IsTrafficLightNearby(YES) FrontRightObjects(4+)) FrontLeftObjects(0))'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_obs = discretizer.state_to_str(initial_state)\n",
    "str_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will take one of these actions:\n",
      "\t-> BRAKE_TURN_RIGHT \tProb: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "possible_actions = pg.question1(initial_state, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_id = AVDiscretizer.get_action_id(Action.BRAKE)\n",
    "best_states = pg.question2(action_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = tuple(( Predicate(PedestrianNearby, [PedestrianNearby(1, 'multiple')]),\n",
    "                Predicate(IsTwoWheelNearby, [IsTwoWheelNearby.YES]),\n",
    "                Predicate(BlockProgress, [BlockProgress.END]),\n",
    "                \n",
    "                Predicate(LanePosition, [LanePosition.RIGHT]),\n",
    "                Predicate(NextIntersection, [NextIntersection.STRAIGHT]),\n",
    "                Predicate(Velocity, [Velocity.STOPPED]),\n",
    "                Predicate(Rotation, [Rotation.FORWARD]),\n",
    "                Predicate(IsStopSignNearby, [IsStopSignNearby.NO]), \n",
    "                Predicate(IsZebraNearby,[IsZebraNearby.NO]),\n",
    "                Predicate(IsTrafficLightNearby, [IsTrafficLightNearby.NO]),\n",
    "                Predicate(FrontRightObjects,[FrontRightObjects(1, 'multiple')]),\n",
    "                Predicate(FrontLeftObjects,[FrontLeftObjects(1, 'multiple')])))\n",
    "#state_2 = av_discretizer.str_to_state(av_discretizer.state_to_str(state))\n",
    "\n",
    "action = policy.act(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Graph with PGBasedPolicyMode.GREEDY and PGBasedPolicyNodeNotFoundMode.FIND_SIMILAR_NODES\n",
      "\n",
      "Supposing I was in (PedestrianNearby(1-3), IsTwoWheelNearby(YES), BlockProgress(END), LanePosition(RIGHT), NextIntersection(STRAIGHT), Velocity(STOPPED), Rotation(FORWARD), IsStopSignNearby(NO), IsZebraNearby(NO), IsTrafficLightNearby(NO), FrontRightObjects(YES), FrontLeftObjects(YES)), if I did not choose to Action.BRAKE was due to...\n",
      "***********************************************\n",
      "* Why did not you perform X action in Y state?\n",
      "***********************************************\n",
      "PGBasedPolicyNodeNotFoundMode.RANDOM_UNIFORM\n",
      "I would have chosen: 1\n",
      "I would have chosen 5 under the following conditions:\n",
      "\tI don't know where I would have ended up\n"
     ]
    }
   ],
   "source": [
    "policy_mode= PGBasedPolicyMode.GREEDY\n",
    "node_not_found_mode = PGBasedPolicyNodeNotFoundMode.FIND_SIMILAR_NODES #PGBasedPolicyNodeNotFoundMode.RANDOM_UNIFORM, \n",
    "action = Action.BRAKE\n",
    "action_id = AVDiscretizer.get_action_id(action)\n",
    "\n",
    "policy_2 = PGBasedPolicy(pg, mode=policy_mode,  node_not_found_mode=node_not_found_mode)\n",
    "print(f'Policy Graph with {policy_mode} and {node_not_found_mode}')\n",
    "print()\n",
    "print(f'Supposing I was in {state}, '\n",
    "    f'if I did not choose to {action} was due to...')\n",
    "policy.pg._normalize() #do i need to normalize before this step?\n",
    "counterfactuals = policy_2.pg.question3(state, action_id, greedy= True, verbose=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Graph Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal situation: knowing the current state unqeuivocally determines the following action and state. To evaluate this we use Entropy.\n",
    "\n",
    "Entropy Interpretation: level of uncertainty of a variable (check PG_position_paper).\n",
    "\n",
    "- H_a(s): 0 --> state s perfectly determines the following action a.\n",
    "Too simple graphs with few nodes show larger action uncertainty, making output less reliable.\n",
    "\n",
    "- H_w(s): 0 --> state s perfectly determines the following state s'.\n",
    "\n",
    "- H(s): 0 --> state s perfectly determines the following pais of s', a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_pg_data = Path('/home/saramontese/Desktop/MasterThesis')\n",
    "\n",
    "#sub_pg = PG.PolicyGraph.from_nodes_and_edges(str(path_pg_data / 'nuscenes_nodes.csv'), str(path_pg_data / 'nuscenes_edges.csv'), env, av_discretizer  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_state = example_scene_df.iloc[0][['x', \"y\", \"velocity\", \"yaw\"]].values\n",
    "#final_state = example_scene_df.iloc[-1][['x', \"y\", \"velocity\", \"yaw\"]].values\n",
    "#print('initial scene state: ', initial_state)\n",
    "#print('final scene state: ', final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_agent = PGBasedPolicy(sub_pg, mode=PGBasedPolicyMode.GREEDY)\n",
    "#reward = env.compute_total_reward(sub_agent, initial_state, final_state, max_steps=100)\n",
    "#print('scene reward before improvement: ', reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reward = env.compute_total_reward(pg)\n",
    "#print('Total PG reward before improvement: ', reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg.policy_iteration(sub_pg)\n",
    "#print('scene reward after improvement: ', env.compute_total_reward(pg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuscenes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
